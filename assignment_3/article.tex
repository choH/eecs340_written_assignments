\documentclass[11pt]{article}
\usepackage{setspace}
\setstretch{1}
\usepackage{amsmath,amssymb, amsthm}
\usepackage{graphicx}
\usepackage{bm}
\usepackage[hang, flushmargin]{footmisc}
\usepackage[colorlinks=true]{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{footnotebackref}
\usepackage{url}
\usepackage{listings}
\usepackage[most]{tcolorbox}
\usepackage{inconsolata}
\usepackage[papersize={8.5in,11in}, margin=1in]{geometry}
\usepackage{float}
\usepackage{caption}
\usepackage{esint}
\usepackage{url}
\usepackage{enumitem}
\usepackage{subfig}
\usepackage{wasysym}
\newcommand{\ilc}{\texttt}
\usepackage{etoolbox}
\usepackage{algorithm}
% \usepackage{algorithmic}
\usepackage[noend]{algpseudocode}
\usepackage{tikz}
\usetikzlibrary{matrix,positioning,arrows.meta,arrows}
\patchcmd{\thebibliography}{\section*{\refname}}{}{}{}

\makeatletter
\renewcommand{\@seccntformat}[1]{}
\makeatother


\begin{document}



\title{\textbf{EECS 340: Assignment 3}}

\author{Shaochen (Henry) ZHONG, \ilc{sxz517} \\ Yuhui ZHANG, \ilc{yxz2052}}
\date{Due and submitted on 02/20/2020 \\ EECS 340, Dr. Koyut{\"u}rk}
\maketitle

% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 1}

\section{(a) $T(n) = bT(n/a) + \Theta(n)$}

For this recurrance, we have a comparsion between $n^{\log_a b}$ and $n$. Since it is given that $1 < a < b$, there must be $\log_a b > 1$. Therefore we may say that there must be a $n^\epsilon = \frac{n^{\log_a b}}{n}$ where $0 < \epsilon = \log_a b - 1$.

Now we have $f(n) = n = O(n^{(\log_a b) - \epsilon})$, where $0 < \epsilon = \log_a b - 1$, we can apply \textit{case 1} of the master theorem and conclude that the solution is $T(n) = \Theta(n)$.

\section{(b) $T(n) = a^2 T(n/a) + \Theta(n^2)$}
For this recurrance, we have a comparsion between $n^{\log_a a^2}$ and $n^2$, thus $n^2$ and $n^2$. As now we have $f(n) = \Theta(n^2)$, we can apply \textit{case 2} of the master theorem and conclude that the solution is $T(n) = \Theta(n \cdot \log n)$


\section{(c) $T(n) = T(\lambda n) + n^{\lambda}$}

We may rewrite it as $T(n) = T\Big(\frac{n}{\frac{1}{\lambda}}\Big) + n^{\lambda}$. Thus, we have a comparsion between $n^{\log_{\frac{1}{\lambda}} 1}$ and $n^{\lambda}$, which is equivalent as $n^0$ and $n^{\lambda}$, then we have $f(n) = \Omega(n^{\log_b a + \epsilon})$ for $\epsilon = \lambda$. We may also show $af(\frac{n}{b}) \leq cf(n)$ for $1 \cdot f\Big(\frac{n}{\frac{1}{\lambda}}\Big) = f(\lambda n)$. Combined, together, we can apply \textit{case 3} of the master theorem and conclude that the solution is $T(n) = \Theta(n^\lambda)$.

\section{(d) $T(n) = aT(\frac{n}{a}) + \Theta(n^{\lambda}(\log n)^b)$}
For this recurrance, we have a comparsion between $n^{\log_a a}$ and $n^{\lambda}(\log n)^b)$, which is equivalent to comparing $n$ and $n^{\lambda}(\log n)^b)$. We may prove that $n$ is polynomially larger than $n^{\lambda}(\log n)^b)$ by analyzing:

\begin{align}
    \text{W.T.S. \ }\lim_{n \to \infty} \frac{n^\epsilon \cdot n^\lambda (\log n)^b}{n} &= 0\\
    \lim_{n \to \infty} \frac{n^\lambda (\log n)^b}{n^{1-\epsilon - \lambda}} &= 0 \nonumber\\
    % \text{Since $n^x$ for any $x > 0$ grows much faster than anything with a base of $\log n$, we must have the following} \nonumber \\
    \Longrightarrow 1-\epsilon - \lambda > 0 &\Rightarrow \epsilon < 1 - \lambda
\end{align}

Thus, we have $f(n) = O(n^{\log_b a - \epsilon})$ for $\epsilon < 1 - \lambda$. Then, we can apply \textit{case 1} of the master theorem and conclude that the solution is $T(n) = \Theta(n)$.




% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 2}


\subsection{(a) For any constant $0 < \alpha < 1$, if $T(n) = T(\alpha n) + T((1-\alpha)n) + \Theta(n)$, then $T(n) = O(n \log n)$}


\paragraph{Guess $T(n) = O(n \log n)$\newline}
Thus there must be constants $c, c'$ for $c, c'\in \mathbb{Z^+}$ s.t. $T(n) \leq cn \log n - c'n$.

\paragraph{Given $T(n) = T(\alpha n) + T((1-\alpha)n) + \Theta(n)$\newline}
\begin{proof}
We may rewrite it as $T(n) = T(\alpha n) + T((1-\alpha)n) + dn$ for $d \in \mathbb{Z^+}$. Assume the claim $T(k) = ck \log k - c'k$ holds true for $T(k)$ for $k \in [1, n)$, and without loss of generality assume that $\alpha \geq 0.5$, we have:

\begin{align}
    T(k + 1) &= T(\alpha(k + 1)) + T((1-\alpha)(k+1)) + d(k + 1) \\
    &\leq [c \cdot \alpha (k + 1) \log(\alpha(k + 1)) - c'(k+1)] + \nonumber\\
    & \ \ \ \ [c \cdot ((1- \alpha)(k + 1))\log((1-\alpha)(k + 1)) - c'(k+1)]+ d(k + 1) \nonumber \\
    &\leq c \cdot \alpha (k + 1) \log(\alpha(k + 1)) + c(1-\alpha)(k + 1)\log(\alpha(k+1)) + d(k + 1) - 2c'(k+1) \nonumber \\
    &\leq (c \alpha + c(k + 1) -  c \alpha) \cdot \log(\alpha(k + 1)) +  d(k + 1) - 2c'(k+1)\nonumber \\
    &\leq c(k + 1) \cdot \log(\alpha(k + 1)) +  (d-2c')(k + 1)\nonumber \\
    &\leq c(k + 1) \cdot \log(k + 1)+  (d-2c')(k + 1)\nonumber \\
    \Longrightarrow T(k + 1) &\leq c(k + 1) \cdot \log(k + 1) \ \ \ \text{for $c'= \frac{1}{2}d$}
\end{align}

As now we have $T(k + 1) \leq c(k + 1) \cdot \log(k + 1)$ for $c'= \frac{1}{2}d$, we may say it is true for $T(k)$ for all $k \in [1, n)$.
\end{proof}


\subsubsection{(b) For any constant $k > 0$, if $T(n) = \Theta(n) + \sum^{k}_{i = 1} T(\frac{n}{2^i})$, then $T(n) = O(n)$}

\paragraph{Guess $T(n) = O(n \log n)$\newline}
Thus, there must be a constant $c$ for $c \in \mathbb{Z^+}$ s.t. $T(n) \leq cn$.

\paragraph{Given $T(n) = \Theta(n) + \sum^{k}_{i = 1} T(\frac{n}{2^i})$\newline}
\begin{proof}
As there must be a constant $d$ for $d \in \mathbb{Z^+}$ s.t. $\Theta(n) \leq dn$ -- and therefore causes $T(n) \leq dn + \sum^{k}_{i = 1} T(\frac{n}{2^i})$ -- with $d$ for $0 < d \leq c - \sum^{k}_{i = 1} c(\frac{1}{2^i})$. Now we may connect the two equations and get

\begin{align}
    T(n) &\leq dn + \sum^{k}_{i = 1} T(\frac{n}{2^i}) \leq cn \\
    &\leq dn + \sum^{k}_{i = 1} c \cdot (\frac{n}{2^i}) \leq cn \nonumber
\end{align}

Assume the claim $T(n) \leq dn + \sum^{k}_{i = 1} T(\frac{n}{2^i}) \leq cn$ holds true for $T(m)$ for $m \in [1, n)$, consider:

\begin{align}
    T(m+1) &\leq d(m + 1) + \sum^{k}_{i = 1} T(\frac{m+1}{2^i}) \\
    &\leq d(m + 1) + \sum^{k}_{i = 1} c \cdot (\frac{m+1}{2^i}) \nonumber \\
    &\leq \underbrace{dm + \sum^{k}_{i = 1} c \cdot (\frac{m}{2^i})}_{= T(m) \leq cm} + \underbrace{d + \sum^{k}_{i = 1} c \cdot (\frac{1}{2^i})}_{= T(1) \leq c(1)} \\
    \Longrightarrow T(m+1) &\leq c(m+1)
\end{align}


As now we have $T(m+1) \leq c(m+1)$ for $c \in \mathbb{Z^+}$, we may say it is true for $T(m)$ for all $m \in [1, n)$.
\end{proof}


% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\section{Problem 3}




% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
% % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % % %
\newpage
\section{Problem 4}

\subsubsection{(a)}

\begin{algorithm}
\caption{QuickMiss(C, D, p, r, missLeft)}\label{QuickMiss}
    \begin{algorithmic}[1]
        \Procedure{QuickMiss}{C, D, p, r, missLeft}
        \If {$p < r$}
            \State $q \gets \textsc{Partition}(C, p, r)$
            \If {$C[q] == D[q]$}
                \State \Return $\textsc{QuickMiss}(C, D, q+1, r, False)$
            \Else
                \State \Return $\textsc{QuickMiss}(C, D, p, q-1, True)$
            \EndIf
        \EndIf
        \If {$missLeft == True$}
            \State \Return $D[p]$
        \Else
            \State \Return $D[r+1]$
        \EndIf
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\begin{algorithm}
\caption{Partition(A, p, r)}\label{Partition}
    \begin{algorithmic}[1]
        \Procedure{Partition}{A, p, r}
        \State $q \gets p$
        \For {$i \gets p$ \textbf{to} $r$}
            \If {$\textsc{Compare-Strings}(A[i], A[r])$}
                \State $\textsc{Swap}(A[i], A[q])$ \Comment{Exchange the two elements.}
                \State $q \gets q+1$
            \EndIf
        \EndFor
        \State $\textsc{Swap}(A[q], A[r])$
        \State \Return $q$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\subsubsection{(b)}

It is known that \textsc{QuickSort} has an average runtime of $O(n\log n)$ due to the fact that it is considered \textit{case 2} of the master theorem: as it has $n$ nodes on each level and with a depth of $\log n$, thus $O(n\log n)$. Our \textsc{QuickMiss} algorithm has a runtime of $O(n)$ due to it only calls \textsc{Partition} on either left portion or right portion to the \ilc{pivot}, but never both. Thus, on each level it will always has less than $n$ nodes, therefore forming a \textit{case 3} of the master theorem. The master theorem suggest, in \textit{case 3} the roots dominate the leaves and therefore determine the runtime of the algorithm -- as \textsc{QuickSort} has $n$ roots at the beginning, we may conclude it has a runtime of $\Theta(n)$.


% \section{References}
%
% \nocite{*}
% \raggedright
% \bibliography{references.bib}
% \bibliographystyle{plain}


\end{document}